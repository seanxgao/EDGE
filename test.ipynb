{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDGE Comprehensive Tests\n",
        "\n",
        "This notebook consolidates all tests and runs them end-to-end:\n",
        "- Setup verification (dependencies and imports)\n",
        "- Ingestion from the repository file `3essay.txt`\n",
        "- Query pipeline (three-stage)\n",
        "- API endpoints via FastAPI TestClient\n",
        "\n",
        "Outputs are stored in the notebook for reproducibility and can be committed to GitHub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All core deps ok: True\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'numpy': True,\n",
              " 'networkx': True,\n",
              " 'sentence-transformers': True,\n",
              " 'faiss-cpu': True,\n",
              " 'fastapi': True,\n",
              " 'pydantic': True,\n",
              " 'uvicorn': True}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Setup verification\n",
        "import sys, os\n",
        "from importlib import import_module\n",
        "\n",
        "checks = [\n",
        "    (\"numpy\", \"numpy\"),\n",
        "    (\"networkx\", \"networkx\"),\n",
        "    (\"sentence_transformers\", \"sentence-transformers\"),\n",
        "    (\"faiss\", \"faiss-cpu\"),\n",
        "    (\"fastapi\", \"fastapi\"),\n",
        "    (\"pydantic\", \"pydantic\"),\n",
        "    (\"uvicorn\", \"uvicorn\"),\n",
        "]\n",
        "\n",
        "results = {}\n",
        "for mod, pkg in checks:\n",
        "    try:\n",
        "        import_module(mod)\n",
        "        results[pkg] = True\n",
        "    except Exception as e:\n",
        "        results[pkg] = False\n",
        "        print(f\"[FAIL] {pkg}: {e}\")\n",
        "\n",
        "print(\"All core deps ok:\", all(results.values()))\n",
        "results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test dir: C:\\Users\\xeangao\\AppData\\Local\\Temp\\edge_nb_test_tv6qgdpp\n",
            "{'sentence_store': {'num_sentences': 104, 'num_chapters': 1, 'num_paragraphs': 1}, 'vector_store': {'num_vectors': 104, 'embedding_dim': 384, 'file_size_bytes': 159744, 'file_size_mb': 0.15}, 'faiss_index': {'index_type': 'flat', 'embedding_dim': 384, 'num_vectors': 104, 'is_trained': False}, 'graph_store': {'nodes': 104, 'edges': 5356, 'density': 1.0}}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "WindowsPath('C:/Users/xeangao/AppData/Local/Temp/edge_nb_test_tv6qgdpp')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ingestion from 3essay.txt (MiniLM + Faiss + Stores)\n",
        "import tempfile\n",
        "from pathlib import Path\n",
        "from pipeline.ingestion import BookIngestionPipeline\n",
        "\n",
        "# Resolve essay path relative to the notebook working directory\n",
        "essay_path = Path.cwd() / \"3essay.txt\"\n",
        "if not essay_path.exists():\n",
        "    raise FileNotFoundError(f\"3essay.txt not found at: {essay_path}\")\n",
        "\n",
        "essay_text = essay_path.read_text(encoding=\"utf-8\", errors=\"ignore\").strip()\n",
        "if not essay_text:\n",
        "    raise ValueError(\"3essay.txt is empty\")\n",
        "\n",
        "# Create temp working directory for all generated artifacts\n",
        "test_dir = tempfile.mkdtemp(prefix=\"edge_nb_test_\")\n",
        "print(\"Test dir:\", test_dir)\n",
        "\n",
        "pipe = BookIngestionPipeline(base_path=test_dir, index_type=\"flat\")\n",
        "pipe.ingest_book(essay_text, batch_size=16, similarity_threshold=0.6)\n",
        "\n",
        "stats = {\n",
        "    \"sentence_store\": pipe.sentence_store.get_stats(),\n",
        "    \"vector_store\": pipe.vector_store.get_stats(),\n",
        "    \"faiss_index\": pipe.faiss_index.get_stats(),\n",
        "    \"graph_store\": pipe.graph_store.get_stats(),\n",
        "}\n",
        "\n",
        "print(stats)\n",
        "assert stats['sentence_store']['num_sentences'] == stats['vector_store']['num_vectors']\n",
        "assert stats['vector_store']['num_vectors'] == stats['faiss_index']['num_vectors']\n",
        "\n",
        "# Persist base path for following cells\n",
        "BASE_PATH = Path(test_dir)\n",
        "BASE_PATH\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the main concept? -> 5 results\n",
            "How does the system work? -> 5 results\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'What is the main concept?': [{'sentence_id': 50,\n",
              "   'text': 'Religion being the chief band of human society, is a happy thing, when itself is well contained within the true band of unity',\n",
              "   'chapter': 'Unknown',\n",
              "   'paragraph_id': 1,\n",
              "   'sentence_id_in_para': 50,\n",
              "   'score': 0.3717085838317871,\n",
              "   'vector_similarity': 0.3434171676635742,\n",
              "   'graph_degree': 103,\n",
              "   'context_coherence': 0.0,\n",
              "   'metadata': {}},\n",
              "  {'sentence_id': 67,\n",
              "   'text': 'It establisheth faith; it kindleth charity; the outward peace of the church, distilleth into peace of conscience; and it turneth the labors of writing, and reading of controversies, into treaties of mortification and devotion',\n",
              "   'chapter': 'Unknown',\n",
              "   'paragraph_id': 1,\n",
              "   'sentence_id_in_para': 67,\n",
              "   'score': 0.3643411219120026,\n",
              "   'vector_similarity': 0.3286822438240051,\n",
              "   'graph_degree': 103,\n",
              "   'context_coherence': 0.0,\n",
              "   'metadata': {}}],\n",
              " 'How does the system work?': [{'sentence_id': 15,\n",
              "   'text': 'First he breathed light, upon the face of the matter or chaos; then he breathed light, into the face of man; and still he breatheth and inspireth light, into the face of his chosen',\n",
              "   'chapter': 'Unknown',\n",
              "   'paragraph_id': 1,\n",
              "   'sentence_id_in_para': 15,\n",
              "   'score': 0.3296658790111542,\n",
              "   'vector_similarity': 0.13933175802230835,\n",
              "   'graph_degree': 103,\n",
              "   'context_coherence': 0.2,\n",
              "   'metadata': {}},\n",
              "  {'sentence_id': 79,\n",
              "   'text': 'Of this I may give only this advice, according to my small model',\n",
              "   'chapter': 'Unknown',\n",
              "   'paragraph_id': 1,\n",
              "   'sentence_id_in_para': 79,\n",
              "   'score': 0.31706658214330674,\n",
              "   'vector_similarity': 0.11413316428661346,\n",
              "   'graph_degree': 103,\n",
              "   'context_coherence': 0.2,\n",
              "   'metadata': {}}]}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Query pipeline test\n",
        "from pipeline.query import QueryPipeline\n",
        "from core.faiss_index import FaissIndex\n",
        "from storage.vector_store import VectorStore\n",
        "from storage.sentence_store import SentenceStore\n",
        "from graph.graph_store import GraphStore\n",
        "from core.embedder_minilm import get_embedder\n",
        "\n",
        "embedder = get_embedder()\n",
        "emb_dim = embedder.get_embedding_dim()\n",
        "\n",
        "faiss_index = FaissIndex.load(str(BASE_PATH / \"faiss.index\"))\n",
        "vector_store = VectorStore(str(BASE_PATH), emb_dim)\n",
        "sentence_store = SentenceStore(str(BASE_PATH / \"sentences.jsonl\"))\n",
        "graph_store = GraphStore(str(BASE_PATH / \"graph.json\"))\n",
        "\n",
        "qp = QueryPipeline(\n",
        "    faiss_index=faiss_index,\n",
        "    vector_store=vector_store,\n",
        "    sentence_store=sentence_store,\n",
        "    graph_store=graph_store\n",
        ")\n",
        "\n",
        "queries = [\n",
        "    \"What is the main concept?\",\n",
        "    \"How does the system work?\",\n",
        "]\n",
        "\n",
        "all_results = {}\n",
        "for q in queries:\n",
        "    res = qp.query(q, top_k=5, initial_k=10)\n",
        "    print(q, \"->\", len(res), \"results\")\n",
        "    all_results[q] = res[:2]\n",
        "\n",
        "all_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "health: {'status': 'healthy', 'pipeline_initialized': True}\n",
            "vectors: 104 sentences: 104\n",
            "query results: 3\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'OK'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# FastAPI endpoints test (TestClient)\n",
        "from fastapi.testclient import TestClient\n",
        "from api.server import app\n",
        "import api.server as api_srv\n",
        "\n",
        "# Reuse qp from previous cell\n",
        "api_srv.query_pipeline = qp\n",
        "\n",
        "client = TestClient(app)\n",
        "\n",
        "# /health\n",
        "h = client.get('/health').json()\n",
        "print('health:', h)\n",
        "assert h['pipeline_initialized'] is True\n",
        "\n",
        "# /stats\n",
        "s = client.get('/stats').json()\n",
        "print('vectors:', s['faiss_index']['num_vectors'], 'sentences:', s['sentence_store']['num_sentences'])\n",
        "\n",
        "# /query\n",
        "payload = {\"query\": \"What is vector search?\", \"top_k\": 3, \"initial_k\": 10}\n",
        "r = client.post('/query', json=payload).json()\n",
        "print('query results:', r['num_candidates'])\n",
        "assert r['num_candidates'] <= 3\n",
        "\n",
        "\"OK\"\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
